{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Machine Learning Techniques II\n",
    "\n",
    "### Local Outlier Factor\n",
    "\n",
    "Anderson Nelson  <br>\n",
    "Date: 11/10/2019 <br>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "So far, I've experimented and studied linear models for outlier detection (PCA), outlier ensemble techniques (Isolation forest). This week I want to experiment with a new type of model proximity outlier detection (Local Outlier Factor). I'm still continuing with the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.models.combination import aom, moa, average, maximization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used throughout the model \n",
    "def correlation_threshold(dataset, threshold):\n",
    "    \"\"\"\n",
    "    Remove columns that do exceeed correlation threshold\n",
    "    \"\"\"\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset\n",
    "    return dataset\n",
    "\n",
    "def outlier_detection(data): \n",
    "    result = []\n",
    "    for value in data: \n",
    "        if value == 0:\n",
    "            result.append('Normal')\n",
    "        else: \n",
    "            result.append('Outlier')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "data = pd.read_csv('../Data/data.csv')\n",
    "data = data.drop(columns = ['Unnamed: 0','Provider City','K Means 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data for columns with numerical values \n",
    "data_subset = data.iloc[:,7:]\n",
    "data_subset_name = data_subset.columns\n",
    "\n",
    "# normalized data to reduced the impact of variables on scale \n",
    "data_subset_scaled = StandardScaler().fit_transform(data_subset)\n",
    "data_subset_scaled = pd.DataFrame(data_subset_scaled, columns=data_subset_name)\n",
    "\n",
    "# any two columns with  correlation of more than 0.8 is removed from the data set, rational is to capture  that add additional value in the data \n",
    "model_data = correlation_threshold(data_subset_scaled, 0.8)\n",
    "print(f' There are {len(model_data.columns)} columns remaining in the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on the first 70% of rows in the data \n",
    "train_split_dim = data_subset.shape[0] * 0.6\n",
    "train_data = data_subset_scaled.loc[1:train_split_dim]\n",
    "test_data = data_subset_scaled.loc[train_split_dim:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor: \n",
    "\n",
    "Measures the local deviation of density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. More precisely, the locality is given by k-nearest neighbors, whose distance is used to estimate the local density. By comparing the local density of a sample to the local densities of its neighbors, one can identify samples that have a substantially lower density than their neighbors. These are considered outliers.\n",
    "\n",
    "There are several ways to tune the parameters of a LOF, and understanding the pros and cons of each approach, an in-depth understanding of the data produces the best results. After experimenting with a few parameters, I realize what parameters are a good fit for my data. \n",
    "\n",
    "LOF requires to estimate the proportion of the outlier that's in your data, calculates the variables that meet this threshold. This approach is fundamentally different from the previous methods I've experimented with. The default parameters are 0.1 for LOF; based on my guess, I'm assuming that less than 10% of providers are committing fraud, and I've decided to that further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on the first 70% of rows in the data \n",
    "train_split_dim = data_subset.shape[0] * 0.7\n",
    "train_data = data_subset_scaled.loc[1:train_split_dim]\n",
    "test_data = data_subset_scaled.loc[train_split_dim:]\n",
    "\n",
    "# filter the main dataset and only includes that passets the correlation test \n",
    "X_test_cluster = data_subset.loc[train_split_dim:].copy()\n",
    "X_test_cluster = X_test_cluster.loc[:, model_data.columns] # dataset used throuhght the document\n",
    "\n",
    "# test subset \n",
    "test_subset = data.loc[train_split_dim:,model_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "Consistent the other models I've analyzed, average covered charges are higher in the outlier category by 2.36x, and out of pocket payment is higher for the outlier categories. At first, it didn't make sense to me that it would be that high for outliers; however, after giving it, some thought it occurred to me that for a hospital to be reimbursed by Medicare, there are numerous compensation and verification hurdles that the hospitals must meet. Those hurdles are costly to the hospital provider, the process can sometimes take months, and there's no guarantee that the hospital will be reimbursed. For the procedures that are more expensive, it represents a huge risk from the providers' standpoint. That risk can be a great incentive for providers to be persuaded to commit fraud. \n",
    "\n",
    "I also see that the providers' labels as outliers also have twice as many traffic as normal. Combined with the point stated earlier, There's a massive revenue collection risk, and cash flow delays that Medicare costs those providers.Given that the average medicare % paid is around the same for both th.e classes, my assumption is that since the providers overcharge for certain procedures, and reduces their risk by collecting a higher percentage upfront from customers. Those procedures tend to be an average more expensive.   \n",
    "\n",
    "The first models produced: 1957 outliers, and providers labels as outliers follows some of the same patterns that I've seen in the previous examples. \n",
    "\n",
    "When comparing average covered charges with out of pocket payments, it's evident that the normal category has a defined range, Max covered charges of 400,000 and out of pocket payments of 15,000. The outlier category contains a higher variance.  For those variables that overlap, it indicates that there are other parameters that separate them. \n",
    "\n",
    "There are clear boundaries for the medicare % paid for the normal values, and medicare % paid to seem to be an import factor to distinguish between outliers and normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "model_1 = LOF(n_neighbors=200,metric='euclidean',contamination=0.04)\n",
    "model_1.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset['LOF_1'] = model_1.fit_predict(test_data)\n",
    "test_subset['LOF_1'] = outlier_detection(test_subset['LOF_1'])\n",
    "test_subset['LOF_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the the test subsgroup\n",
    "round(test_subset.groupby('LOF_1').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std of the test subgroup\n",
    "round(test_subset.groupby('LOF_1').std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Out of Pocket Payment\", col = \"LOF_1\",hue=\"LOF_1\",style=\"LOF_1\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset, palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Medicare % Paid\", col = \"LOF_1\",hue=\"LOF_1\",style=\"LOF_1\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "For the second model, I wanted to dial down the number of samples used and observe the impact on the results. Similar to model 1, Averaged covered charges are about 2x higher in the outlier label. The covered charges standard deviation is less in the outliers of model 2 vs. model 1. \n",
    "\n",
    "Similar to model 1, visualizing the results highlights the concentration of the normal labels and variability of the outlier labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "model_2 = LOF(n_neighbors=50,contamination=0.05)\n",
    "model_2.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset['LOF_2'] = model_2.fit_predict(test_data)\n",
    "test_subset['LOF_2'] = outlier_detection(test_subset['LOF_2'])\n",
    "test_subset['LOF_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the the test subsgroup\n",
    "round(test_subset.iloc[:,3:].groupby('LOF_2').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std of the test subgroup\n",
    "round(test_subset.groupby('LOF_2').std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"total_discharge_ratio\", col = \"LOF_2\",hue=\"LOF_2\",style=\"LOF_2\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Medicare % Paid\", col = \"LOF_2\",hue=\"LOF_2\",style=\"LOF_2\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "model_3 = LOF(contamination=0.01,metric='l1')\n",
    "model_3.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset['LOF_3'] = model_3.fit_predict(test_data)\n",
    "test_subset['LOF_3'] = outlier_detection(test_subset['LOF_3'])\n",
    "test_subset['LOF_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the the test subsgroup\n",
    "round(test_subset.groupby('LOF_3').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std of the the test subsgroup\n",
    "round(test_subset.groupby('LOF_3').std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"total_discharge_ratio\", col = \"LOF_3\",hue=\"LOF_3\",style=\"LOF_3\",  size=\"Coverage Ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Medicare % Paid\", col = \"LOF_3\",hue=\"LOF_3\",style=\"LOF_3\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models \n",
    "\n",
    "Utilizing only 1 model for your prediction can be dangerous, especially since it there's a lot of subjectivity in how the paramaters were determined. In this section I will combine the models using the average and maxium of maximum technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predictions of the training data can be obtained by clf.decision_scores_.\n",
    "# It is already generated during the model building process.\n",
    "train_scores = pd.DataFrame({'Model_1': model_1.decision_function(train_data),\n",
    "                             'Model_2': model_2.decision_function(train_data),\n",
    "                             'Model_3': model_3.decision_function(train_data)\n",
    "                            })\n",
    "\n",
    "# The predictions of the test data need to be predicted using clf.decision_function(X_test)\n",
    "test_scores  = pd.DataFrame({'Model_1': model_1.decision_function(test_data),\n",
    "                             'Model_2': model_2.decision_function(test_data),\n",
    "                             'Model_3': model_3.decision_function(test_data) \n",
    "                            })\n",
    "\n",
    "# Although we did standardization before, it was for the variables.\n",
    "# Now we do the standardization for the decision scores\n",
    "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_by_average = average(test_scores_norm)\n",
    "plt.hist(model_by_average, bins='auto')\n",
    "plt.title('Model By Average Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset['Model_by_avg'] = np.where(model_by_average > 2, 'Oultier', 'Normal')\n",
    "test_subset['Model_by_avg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(test_subset.groupby('Model_by_avg').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Out of Pocket Payment\", col = \"Model_by_avg\",hue=\"Model_by_avg\",style=\"Model_by_avg\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Medicare % Paid\", col = \"Model_by_avg\",hue=\"Model_by_avg\",style=\"Model_by_avg\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination by max\n",
    "y_by_maximization = maximization(test_scores_norm)\n",
    "plt.hist(y_by_maximization, bins='auto')\n",
    "plt.title(\"Combination by max\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset['model_by_max'] = np.where(y_by_maximization<4, 'Normal', 'Outlier')\n",
    "test_subset['model_by_max'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(test_subset.groupby('model_by_max').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(test_subset.groupby('model_by_max').std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Out of Pocket Payment\", col = \"model_by_max\",hue=\"model_by_max\",style=\"model_by_max\",  size=\"mean_discharge_per_drg_state_region\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Average Covered Charges\", y=\"Medicare % Paid\", col = \"model_by_max\",hue=\"model_by_max\",style=\"model_by_max\",  size=\"ratio_oop_payment_ratio\",\n",
    "            sizes=(40, 400),edgecolor=\".2\", linewidth=.5, alpha=.5,\n",
    "            height=6, data=test_subset,palette=sns.color_palette(\"husl\", 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "\n",
    "One of the critical lessons I learned in this analysis is balancing. Understanding the motives of the involved parties allows us to evaluate the results of the models and letting the model dictate the story. While the model can produce results that defy logic, however sometimes, it highlights the relationship that you didn't consider. Domain knowledge allows you to distinguish between the two classes.\n",
    "\n",
    "Consistently, we have that the providers at the higher end of the pricing spectrum, and high out of pocket payments are identitfied as potential candidate for investigation. This behaviors can be explained by incentivized by the ineffeiceies of Medicare, providers can be incentivized to recover their cost upfront from cusotmer, and inflate procedure expenses.\n",
    "\n",
    "Similar to last week, the LOF algorithm relies on me to be abie to correcty identify the paramters that captures the tru relationahip of the model. By combing different models, we are taking advantage of the wisdom of the crowd and reduce the reliance on one technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "\n",
    "[LOF: Identifying Density-Based Local Outliers](https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
